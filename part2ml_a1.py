# -*- coding: utf-8 -*-
"""part2ML_A1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O7GJnxb1lpMQcaRhokB6aaRht7qI37ZA

Part 2: Naive Bayes, KNN, and Decision Tree
## New Section
"""

# Data manipulation
import pandas as pd
import numpy as np

# Data splitting and preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Models
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

# Evaluation metrics
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Optional: visualization
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("/content/Social_Network_Ads.csv")

df.head(10)

df.drop('User ID', axis=1, inplace=True)

df_encoded = pd.get_dummies(df, columns=[ 'Gender'], dtype=int)

df_encoded = pd.get_dummies(df, columns=['Purchased'], dtype=int)

#Standardize the feature columns (Age, EstimatedSalary).
scaler = StandardScaler()
df_encoded[['Age', 'EstimatedSalary']] = scaler.fit_transform(df_encoded[['Age', 'EstimatedSalary']])

"""### Model Building"""

# Features and target
X = df[['Age', 'EstimatedSalary']]  # independent variables
y = df['Purchased']                # dependent variable (target)

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42)

# Check shapes
print("Training set:", X_train.shape)
print("Test set:", X_test.shape)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, accuracy_score

nb_model = GaussianNB()
nb_model.fit(X_train_scaled, y_train)
y_pred_nb = nb_model.predict(X_test_scaled)

print("Gaussian Naive Bayes:")
print(classification_report(y_test, y_pred_nb))

"""### KNeighborsClassifier"""

from sklearn.neighbors import KNeighborsClassifier

for k in [3, 5, 7]:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train_scaled, y_train)
    y_pred_knn = knn.predict(X_test_scaled)

    print(f"\nKNN (k={k}):")
    print(classification_report(y_test, y_pred_knn))

"""## DecisionTreeClassifier"""

from sklearn.tree import DecisionTreeClassifier

# Gini
dt_gini = DecisionTreeClassifier(criterion='gini', random_state=42)
dt_gini.fit(X_train, y_train)
y_pred_gini = dt_gini.predict(X_test)

print("\nDecision Tree (Gini):")
print(classification_report(y_test, y_pred_gini))

# Entropy
dt_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42)
dt_entropy.fit(X_train, y_train)
y_pred_entropy = dt_entropy.predict(X_test)

print("\nDecision Tree (Entropy):")
print(classification_report(y_test, y_pred_entropy))

"""## Model Evaluation"""

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix

def evaluate_model(name, y_true, y_pred):
    print(f"\n{name} Evaluation Metrics:")
    print("Accuracy:", accuracy_score(y_true, y_pred))
    print("Precision:", precision_score(y_true, y_pred))
    print("Recall:", recall_score(y_true, y_pred))
    print("F1 Score:", f1_score(y_true, y_pred))

    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    fig, ax = plt.subplots(figsize=(5, 4))  # Set figure size to make it visible
    disp.plot(ax=ax, cmap='Greens', values_format='d')
    plt.title(f'{name} - Confusion Matrix')
    plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

evaluate_model("Gaussian Naive Bayes", y_test, y_pred_nb)
evaluate_model("KNN (k=5)", y_test, y_pred_knn)
evaluate_model("Decision Tree (Gini)", y_test, y_pred_gini)
evaluate_model("Decision Tree (Entropy)", y_test, y_pred_entropy)

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def plot_decision_boundary(model, X, y, title):
    # Define bounds of the domain
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1

    # Create a meshgrid of points with distance h between them
    h = 0.01
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))

    # Predict the function value for the whole grid
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    # Plot the contour and training examples
    plt.figure(figsize=(8, 6))
    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Paired)
    sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, palette='Set1', edgecolor='k', alpha=0.8)
    plt.title(title)
    plt.xlabel('Age (scaled)')
    plt.ylabel('EstimatedSalary (scaled)')
    plt.show()

from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

# Example: training models on scaled training data
naive_bayes_model = GaussianNB()
naive_bayes_model.fit(X_train_scaled, y_train)

knn_model = KNeighborsClassifier(n_neighbors=5)  # or 3, 7
knn_model.fit(X_train_scaled, y_train)

decision_tree_model = DecisionTreeClassifier(criterion='gini')  # or criterion='entropy'
decision_tree_model.fit(X_train_scaled, y_train)

plot_decision_boundary(naive_bayes_model, X_train_scaled, y_train, "Gaussian Naive Bayes Decision Boundary")
plot_decision_boundary(knn_model, X_train_scaled, y_train, "KNN Decision Boundary")
plot_decision_boundary(decision_tree_model, X_train_scaled, y_train, "Decision Tree Decision Boundary")

results = {}

def evaluate_and_store(name, y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)

    results[name] = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1
    }
    print(f"{name} evaluated.")

# Evaluate each model
evaluate_and_store("Gaussian Naive Bayes", y_test, y_pred_nb)
evaluate_and_store("KNN (k=5)", y_test, y_pred_knn)
evaluate_and_store("Decision Tree (Gini)", y_test, y_pred_gini)
evaluate_and_store("Decision Tree (Entropy)", y_test, y_pred_entropy)

# Display results
import pandas as pd
df_results = pd.DataFrame(results).T  # Transpose to have models as rows
print(df_results)